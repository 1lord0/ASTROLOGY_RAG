import streamlit as st
import os
import google.generativeai as genai
from google.generativeai import GenerativeModel
import json

# -----------------------------
# 0) API AYARLARI
# -----------------------------
if "GEMINI_API_KEY" not in st.secrets:
    st.error("âŒ HATA: 'GEMINI_API_KEY', Streamlit Secrets'ta tanÄ±mlanmalÄ±dÄ±r.")
    st.stop()
    
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
llm = GenerativeModel("gemini-1.5-flash")

# -----------------------------
# 1) BASIT JSON VEKTÃ–R DEPOSU
# -----------------------------
@st.cache_data
def load_documents():
    """Chroma DB yerine basit JSON kullan"""
    json_path = "documents.json"
    
    # EÄŸer JSON yoksa, chroma_db'den oku (bir kerelik)
    if not os.path.exists(json_path):
        st.warning("âš ï¸ documents.json bulunamadÄ±. LÃ¼tfen lokal olarak oluÅŸturun.")
        return []
    
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# -----------------------------
# 2) BASIT ARAMA FONKSÄ°YONU
# -----------------------------
def simple_search(query, documents, k=3):
    """Keyword-based basit arama"""
    query_words = set(query.lower().split())
    
    scores = []
    for doc in documents:
        doc_words = set(doc['content'].lower().split())
        score = len(query_words & doc_words)  # Ortak kelime sayÄ±sÄ±
        scores.append((score, doc))
    
    # Skorlara gÃ¶re sÄ±rala
    scores.sort(reverse=True, key=lambda x: x[0])
    return [doc for score, doc in scores[:k]]

# -----------------------------
# 3) RAG PIPELINE
# -----------------------------
def ask_rag(question):
    """KullanÄ±cÄ± sorusuna RAG ile cevap verir."""
    
    docs = load_documents()
    if not docs:
        return "âŒ DÃ¶kÃ¼manlar yÃ¼klenemedi. LÃ¼tfen documents.json dosyasÄ±nÄ± oluÅŸturun.", []
    
    # Basit arama
    results = simple_search(question, docs, k=3)
    
    if not results:
        return "âŒ Ä°lgili dÃ¶kÃ¼man bulunamadÄ±.", []
    
    # Context oluÅŸtur
    context = "\n\n".join([doc['content'] for doc in results])
    
    # Prompt oluÅŸtur
    prompt = f"""Sen bir astroloji uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki bilgileri kullanarak soruyu yanÄ±tla.

BAÄLAM:
{context}

SORU: {question}

YANIT (TÃ¼rkÃ§e ve detaylÄ±):"""
    
    try:
        # Gemini API Ã§aÄŸrÄ±sÄ±
        response = llm.generate_content(prompt)
        return response.text, results
    except Exception as e:
        st.error(f"API HatasÄ±: {str(e)}")
        return None, []

# -----------------------------
# 4) STREAMLIT UI
# -----------------------------
st.title("ğŸ”® Astrology RAG Chatbot")
st.write("Astroloji hakkÄ±nda her ÅŸeyi sorabilirsiniz.")

# Debug info
with st.expander("ğŸ”§ Sistem Bilgisi"):
    docs = load_documents()
    st.info(f"ğŸ“Š Toplam dÃ¶kÃ¼man: {len(docs)}")
    if docs:
        st.success("âœ… DÃ¶kÃ¼manlar yÃ¼klendi")

question = st.text_input("Sorunuz:")

if st.button("Sorgula") or question:
    if not question or not question.strip():
        st.warning("âš ï¸ LÃ¼tfen geÃ§erli bir soru girin.")
    else:
        with st.spinner("YÄ±ldÄ±zlara danÄ±ÅŸÄ±lÄ±yor..."):
            answer, chunks = ask_rag(question)
            
            if answer:
                st.subheader("ğŸŒŸ Cevap")
                st.write(answer)
                
                if chunks:
                    with st.expander("ğŸ” Kaynak DÃ¶kÃ¼manlar"):
                        for i, c in enumerate(chunks, 1):
                            st.markdown(f"**Kaynak {i}:**")
                            st.text(c['content'][:300] + "...")
                            st.divider()
